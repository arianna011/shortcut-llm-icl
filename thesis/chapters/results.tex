\documentclass[../main.tex]{subfiles}
% !TeX root = ../main.tex
\graphicspath{{\subfix{../assets/}}}
\begin{document}

\chapter{Experimental Evaluation}
\label{chap:results}

Several experiments were conducted to evaluate the effectiveness of the proposed RepE-based framework for shortcut detection and mitigation.  
Section~\ref{sec:setup} describes the experimental setup, while Section~\ref{sec:results} presents and discusses the obtained results. The experiments aim to determine whether latent shortcut directions can be reliably extracted from LLM representations and whether their manipulation through RepControl leads to measurable improvements in model behavior under In-Context Learning (ICL).

\section{Experimental Setup}
\label{sec:setup}

In order to evaluate the framework proposed in Section \ref{sec:method}, two main objectives were considered:

\begin{itemize}
    \item to assess whether shortcut-related mechanisms can be identified within the model’s latent space, thus evaluating \textit{shortcut detection};
    \item to test the effectiveness of the \textit{shortcut mitigation} procedure based on RepControl interventions, determining whether steering the internal representations of LLMs can effectively reduce shortcut-driven behavior under ICL.
\end{itemize} 

Accordingly, this section describes the experimental configuration adopted for both stages, detailing the model, datasets, prompt design and implementation settings used in the analysis.\\

\subsection{Model}

All experiments were carried out using the \textit{Mistral 7B Instruct v0.1} model\footnote{Available at \url{https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1}}. 
This choice was motivated by both methodological and practical considerations: Mistral 7B Instruct is a decoder-only transformer with open weights, which allows direct access to the model’s internal hidden states, an essential requirement for applying the RepE-based framework. Moreover, despite its moderate size, it demonstrates strong instruction-following and reasoning capabilities, making it representative of modern LLMs while remaining computationally efficient. From a practical perspective, the experiments were conducted on free Google Colab environments, where hardware memory is limited. To enable inference and activation extraction within these constraints, the model was loaded in 4-bit precision using the \textit{bitsandbytes} quantization library. This approach significantly reduced GPU memory usage with minimal degradation in representational fidelity, allowing the experiments to be performed efficiently without altering the qualitative behavior of the model.\\

Mistral 7B Instruct v0.1 follows the transformer-decoder architecture introduced by \textit{Mistral AI}, featuring 32 transformer layers and approximately 7.3 billion parameters.  
Each layer consists of a multi-head self-attention block followed by a feed-forward (MLP) block, both wrapped with \textit{RMSNorm} normalization instead of the standard LayerNorm, improving numerical stability in low-precision inference.  
The attention mechanism uses a \textit{Grouped Query Attention} (GQA) configuration with 8 query heads per group to enhance inference efficiency.  
Positional information is encoded using \textit{rotary positional embeddings} (RoPE), and the model employs \textit{SwiGLU} activation functions in the feed-forward layers.  
The hidden dimension is 4096, with an intermediate feed-forward dimension of 14336 and a context window of up to 8192 tokens \citep{jiang2023mistral7b}.\\

For the purpose of this work, hidden-state representations were extracted after each RMSNorm layer at the output of the transformer blocks\footnote{Specifically, the hidden representations referred to as $\{H_l\}_{l \in layers}$ correspond to tensors of size $(batch\ size, sequence\ length, hidden\ dimension)$, where the first tensor represents the embedding layer output and each subsequent tensor represents the post-layer activations of the corresponding transformer block.
}.
These activations correspond to the contextual embeddings used internally by the model to predict the next token and thus provide the representational substrate targeted by the RepE framework.  
Accessing layerwise activations in this way enables the identification and manipulation of latent directions corresponding to shortcut-related mechanisms.\\

Although the Mistral 7B architecture shares many similarities with LLaMA 2 models (such as the use of rotary positional embeddings and decoder-only transformer blocks), it introduces several design improvements that make it particularly suitable for this study.  
First, Mistral's GQA enables faster computation and lower GPU memory footprint during layerwise extraction and manipulation of activations. Second, as already mentioned, the use of RMSNorm offers better numerical stability when operating under low-precision quantization settings such as the 4-bit configuration adopted here.  
Finally, empirical evaluations have shown that Mistral 7B consistently outperforms LLaMA 2 models of comparable size on most standard benchmarks \citep{jiang2023mistral7b}, suggesting that its latent representations are richer and more semantically structured, an advantageous property for analyzing shortcut mechanisms within the representation space.\\

\subsection{Datasets and prompt design}
\label{subsec:datasets}

Most of the conducted experiments are based on the \textit{Textual Entailment Recognition} (TER) task in Natural Language Processing (NLP).  
Also known as \textit{Natural Language Inference} (NLI), TER is an application-independent task that consists in automatically determining whether a directional entailment relationship holds between two text fragments.  
Given a \textit{premise} $P$ and a \textit{hypothesis} $H$, the goal is to decide whether $H$ is \textit{entailed} by $P$, that is, whether $H$ can be considered most likely true if $P$ is true.  
The task can be formulated either as a binary classification problem, where text pairs are labeled as \textit{entailment} or \textit{non-entailment}, or as a three-way classification variant, where they are categorized as \textit{entailment}, \textit{contradiction}, or \textit{neutral}. For example, given the following prompt:
\begin{quote}
\textit{Premise:} A boy is playing in the garden.\\
\textit{Hypothesis:} There is a boy in the garden.\\
\textit{Classification:} ?
\end{quote}
the correct label is \textit{entailment}.  Conversely, for:
\begin{quote}
\textit{Premise:} Luna is barking loudly.\\
\textit{Hypothesis:} Luna is human.\\
\textit{Classification:} ?
\end{quote}
the correct label is \textit{contradiction}.\\

The TER task can be seen as a general evaluation tool for testing the inference capabilities of NLP systems, which all share the need to process and understand natural language, and serves as a unifying framework for reformulating a variety of NLP tasks. For example, \textit{question answering} can be recast as TER by converting each candidate answer into an hypothesis formed from the question-answer pair and ranking them according to the degree of entailment with respect to the given premise. Similarly, in \textit{text summarization} and \textit{machine translation}, candidate summaries or translations can be treated as hypotheses whose quality is estimated by the extent to which they are entailed by the original text \citep{survey2022}.  
Furthermore, TER is particularly well-suited for the present work since it is associated with several well-documented and easily observable shortcut phenomena (e.g. lexical overlap, negation cues, position bias), making it an ideal testbed for studying shortcut detection and mitigation via the proposed RepE-based framework.\\

\noindent \textbf{Training Datasets.} The training datasets referred to as "NLP Shortcut Dataset" in Figure \ref{fig:myrepeframework} were thus taken from the \textit{ShortcutSuite} repository \citep{yuan2024llmsovercomeshortcutlearning}, which provides TER instances augmented with different types of injected shortcuts. In particular, the datasets selected for this work are those derived from the Multi-Genre Natural Language Inference (MNLI) corpus \citep{williams2018broadcoveragechallengecorpussentence}, a 433k-example collection for three-way textual entaiment, spanning ten text genres across both spoken and written English (e.g. telephone speech, government documents, fiction). ShortcutSuite uses a balanced subset of 3,000 premise-hypothesis pairs sampled from the MNLI development set to generate "shortcut-injected" alterations of the original text with the following shortcut types:

\begin{itemize}
    \item \textbf{\textit{Negation}}: Random tautologies containing negation words are appended to the original hypothesis to test whether LLMs are overly sensitive to the mere presence of negation, even when it does not change the underlying logical relationship.  
    For example:
    \begin{quote}
        \small
        \textit{Premise:} Children will enjoy the little steam train that loops around the bay to Le Crotoy in the summer.\\[4pt]
        \textit{Hypothesis (clean):} There is a steam train looping around the bay to Le Crotoy.\\[4pt]
        \textit{Hypothesis (dirty):} There is a steam train looping around the bay to Le Crotoy \textbf{and false is not true}. 
    \end{quote} 
    This corresponds to a form of \textit{Lexicon} shorcut (see Section \ref{sec:types_icl}).
    \vspace{1em}

    \item \textbf{\textit{Position}}: Tautological sentences are inserted at different positions within the premise to evaluate whether the model relies on positional cues rather than semantic content. For instance:
    \begin{quote}
        \small
        \textit{Premise (clean):} Also, the final rule is not intended to have any retroactive effect, and administrative procedures must be exhausted prior to any judicial challenge to the provisions of the rule.\\[4pt]
        \textit{Premise (dirty):}  \textbf{Red is red and red is red and red is red and red is red and red is red.} Also, the final rule is not intended to have any retroactive effect, and administrative procedures must be exhausted prior to any judicial challenge to the provisions of the rule.\\[4pt]
        \textit{Hypothesis:} The final rule isn't meant to have a retroactive effect.
    \end{quote}
    
    \vspace{1em}
    \item \textbf{\textit{Style}}: The original premise is paraphrased into a Bible-like style using the STRAP model, in order to test whether stylistic features influence model predictions independently of semantics. Example:
    \begin{quote}
        \small
        \textit{Premise (clean):} “You and your friends are not welcome here,” said Severn.\\[4pt]
        \textit{Premise (dirty):} \textbf{And Severn said unto him, Thou and thy friends are not welcome here, said he.}\\[4pt]
        \textit{Hypothesis:} Severn said the people were not welcome there.
    \end{quote}
\end{itemize}

These three shortcut types were chosen over the HANS-style shortcuts (\textit{Lexical Overlap}, \textit{Subsequence}, and \textit{Constituent}) included in the ShortcutSuite because the RepE framework requires contrastive pairs where the clean and shortcut-injected examples correspond exactly to the same original instance.  
Negation, Position, and Style were the only shortcut sets that explicitly preserve this linkage through shared identifiers across the provided tables, enabling the construction of aligned clean-dirty pairs needed for RepReading.\\

Before being fed to the RepReader, each example was formatted using a simple zero-shot ICL prompt template containing the instruction \texttt{"Decide if the hypothesis is entailed by the premise"}. Below is a complete instance of a contrastive pair of prompts used to extract a latent shorcut direction.\\

\begin{tcolorbox}[
  colback=white,
  colframe=gray!40,
  boxrule=0.4pt,
  arc=2pt
]
    \texttt{USER: Decide if the hypothesis is entailed by the premise.\\
     Premise: And yet, we still lack a set of global accounting and reporting standards that reflects the globalization of economies, enterprises, and markets.\\
     Hypothesis: The globalization of economies is not reflected in global accounting standards.\\
    ASSISTANT:} 
\end{tcolorbox} 

\vspace{0.5em}

\begin{tcolorbox}[
  colback=white,
  colframe=gray!40,
  boxrule=0.4pt,
  arc=2pt
]
     \texttt{USER: Decide if the hypothesis is entailed by the premise.\\
     Premise: And yet, we still lack a set of global accounting and reporting standards that reflects the globalization of economies, enterprises, and markets.\\
     Hypothesis: The globalization of economies is not reflected in global accounting standards \textbf{and green is not red}.\\
    ASSISTANT:}
\end{tcolorbox}

\vspace{1em}

\noindent Differently from the original RepE experiments \citep{zou2025representationengineeringtopdownapproach}, in this work the stimuli for the \textit{function} extraction do not rely on model-generated continuations guided by differentiated instructions (e.g. "answer like an honest person" vs "answer like a dishonest person").  
Instead, the task instances themselves serve as stimuli: the model is not required to answer, but only to process the input prompts, thereby generating hidden-state activations that ideally differ between clean and shortcut-augmented versions of the same example.\\


\noindent \textbf{Evaluation Datasets.} The datasets employed for evaluating the proposed methodology (referred to as "NLP Dataset" in Figure \ref{fig:myrepeframework}) are standard NLP benchmarks for tasks such as TER. In particular, in addition to the already cited MNLI, the Recognizing Textual Entailment (RTE) dataset \citep{dagan2006rte} from the GLUE benchmark is used. RTE consists of sentence pairs for entailment vs. not-entailment classification, drawn from the annual RTE challenges held between 2005 and 2011, and built primarily from news and Wikipedia text. While MNLI serves as an in-distribution testbed for shortcut detection and mitigation, given that the shortcut training datasets are derived from it, RTE provides an opportunity to test whether the proposed approach generalizes to naturally occurring shortcuts in a standard entailment benchmark.\\

For the practical evaluation, the UniBias framework \citep{zhou2024unibiasunveilingmitigatingllm} was used to construct ICL prompts for each test instance.  
In a $k$-shot setting, the ICL context is built as follows:

\begin{itemize}
    \item when $k = 0$, the prompt consists of a dataset-specific task instruction (e.g. for MNLI: \textit{"Given the premise, are we justified in saying the hypothesis? yes, no, or maybe?"}) followed by the test instance;
    \item when $k > 0$, the prompt contains $k$ demonstration examples for each label class, randomly sampled from the dataset training split, followed by the test instance. No explicit task instruction is included in this setting.
\end{itemize}

\noindent For illustration, in a 1-shot setting, an actual RTE prompt seen by the model at test time may be:

\begin{quote}
\small
\textit{Premise:} Former Prime Minister Rafik Hariri, also a prominent anti-Syria political figure, was killed in a suicide bombing in February last year, which led to rising anti-Syrian waves and the withdrawal of Syrian troops from Lebanon.\\
\textit{Hypothesis:} Syrian troops have been withdrawn from Lebanon after the murder of Rafik Hariri.\\
\textit{Answer: yes}

\vspace{0.4em}

\textit{Premise:} The organizers of the 15th International AIDS Conference, scheduled for next month in Bangkok, Thailand, on Saturday responded to press reports that a prominent hotel in Bangkok discriminated against HIV-positive visitors attending a different conference this month.\\
\textit{Hypothesis:} HIV-positive visitors take part in the 15th International AIDS Conference.\\
\textit{Answer: no}

\vspace{0.4em}

\textit{Premise:} Dana Reeve, the widow of the actor Christopher Reeve, has died of lung cancer at age 44, according to the Christopher Reeve Foundation.\\
\textit{Hypothesis:} Christopher Reeve had an accident.\\
\textit{Answer:}
\end{quote}

To investigate the generalizability of the proposed shortcut mitigation framework beyond entailment tasks, additional NLP benchmarks were considered.  
Specifically, the following datasets were employed:

\begin{itemize}
    \item \textbf{COPA} \citep{gordon-etal-2012-semeval}: a commonsense causal reasoning task in which the model chooses between two plausible alternatives to complete a causal relation with a given premise;
    \item \textbf{CR} \citep{turney2002thumbsthumbsdownsemantic}: a binary sentiment classification dataset consisting of customer reviews labeled as positive or negative;
    \item \textbf{SST2} \citep{socher-etal-2013-recursive}: the Stanford Sentiment Treebank binary classification task on movie reviews;
    \item \textbf{WiC} \citep{pilehvar-camacho-collados-2019-wic}: the Word-in-Context benchmark, which tests word sense disambiguation by asking whether a target word has the same meaning in two different sentences;
    \item \textbf{ARC} \citep{clark2018thinksolvedquestionanswering}: a multiple-choice question answering dataset for grade-school science questions;
    \item \textbf{MMLU} \citep{hendrycks2021measuringmassivemultitasklanguage}: the Massive Multitask Language Understanding benchmark, a large-scale multiple-choice collection spanning diverse subjects such as mathematics, history, law and computer science.
\end{itemize}

\noindent Evaluating the framework on tasks beyond entailment is also valuable for assessing whether shortcut-related representations learned by LLMs exhibit any degree of cross-task consistency.  
If similar shortcut directions emerge across heterogeneous datasets, ranging from sentiment analysis to causal reasoning or word-sense disambiguation, this would suggest the presence of shared latent mechanisms through which LLMs internalize and exploit superficial cues.  
Conversely, a lack of transferability would indicate that shortcut reliance is highly task-specific, reinforcing the need for targeted analyses.  
Thus, examining multiple NLP tasks provides insights into whether shortcut representations capture generalizable patterns or remain confined to the TER setting from which they were extracted.\\

Given the exploratory nature of the experiments and the limited computational resources available, the test set sizes were kept modest.  
Table \ref{tab:testsets} reports the test sets used in this work, along with their source splits and number of examples.

\begin{table}[ht]
\centering
\begin{tabular}{l c c}
\toprule
\textbf{Name} & \textbf{Source} & \textbf{Size} \\
\midrule
MNLI & subset of MNLI "validation matched" split & 500 \\
RTE & RTE validation split & 277 \\
COPA & COPA validation split & 100 \\
CR & CR test split & 376 \\
SST2 & SST2 validation split & 872 \\
WIC & WiC validation split & 638 \\
ARC & ARC test split & 1170 \\
MMLU & subset of MMLU test split & 2000 \\
\bottomrule
\end{tabular}
\vspace{6pt}
\caption{Evaluation test sets used in this work}
\label{tab:testsets}
\end{table}



\section{Results and Analysis}
\label{sec:results}

This section presents the results obtained from the experiments evaluating the RepE-based approach to shortcut detection and mitigation.  
Shortcut detection (Section \ref{sec:detres}) is assessed qualitatively on selected test instances, while shortcut mitigation (Section \ref{sec:mitres}) is evaluated systematically across multiple hyperparameter configurations on different test sets (Table \ref{tab:testsets}).
To support reliable tracking and reproducibility, all experiments were logged using the Weights \& Biases (W\&B) platform, which recorded both input configurations and output metrics.  
In addition, the full sets of prompts and activation files used in each run were stored as artifacts, ensuring that every experiment can be reproduced precisely.

\subsection{Shortcut Detection Results}
\label{sec:detres}

To qualitatively assess the effectiveness of the RepE-based framework for shortcut detection, the following experiment was conducted. Given a RepReader $R$ trained on a random subset of the negation shortcut dataset\footnote{The negation shortcut type was selected because it is easier to visualize, being tied to explicit lexical markers such as "not", and because its effect on the model’s predictions is straightforward: an entailment relation is often incorrectly interpreted as non-entailment.} from the ShortcutSuite and two contrastive test statements $s1$ and $s2$ (exhibiting or non-exhibiting an explicit shortcut cue), scores $A_{l,t}$ are computed to measure, at different layers $l$ and token positions $t$, the degree to which the model’s internal representations of $s1$ and $s2$ align with the shortcut direction identified by $R$. The scores computation proceeds as follows:

\begin{itemize}
    \item \textbf{Encoding of the input statements.} The sentences $s1$ and $s2$ are fed to the frozen target LLM to obtain hidden representations $h_{l}$ for each layer $l$ and token position $t$. Optionally, the model's generated continuations for $s1$ and $s2$ are appended to the input before extracting the hidden representations, allowing shortcut effects to surface in both the prompt and the generation.
    
    \item \textbf{Projection onto the shortcut direction.} For each layer $l$ and token position $t$, the hidden representations $h_{l, t}$ are projected onto the shortcut direction $V_l$ inferred by the RepReader $R$ for that layer. The projection is then multiplied by the corresponding sign $S_l$: \[
    A_{l,t} = \langle h_{l,t}, V_l \rangle \cdot S_l
    \]

    \item \textbf{Averaged projections.} Given a selected set $L$ of hidden layers, the scores $A_{l,t}$ are averaged across all layers in $L$ to obtain a mean shortcut-alignmet score for each token position 
    \[
    A^{\text{mean}}_{t} = \frac{1}{|L|} \sum_{l \in L} A_{l,t}
    \]
    This aggregation highlights persistent shortcut activation patterns across layers rather than isolated spikes.
\end{itemize}

\vspace{1em}

Scores $A_{l,t}$ can be visualized as an heatmap across layers and token positions, a representation referred to as a \textit{LAT scan} in the original RepE paper. In the honesty experiments, the authors observed clearly distinguishable scans for honest versus dishonest generations, with the former showing a substantially stronger correlation with the learned "honesty direction". In the shortcut detection setting of the present work, the contrast between the scans of the two test statements is less pronounced. Nonetheless, subtle differences in the LAT scans can still be observed, indicating that the shortcut direction captured by the RepReader is activated to a different extent across the two inputs.\\

\noindent Figures \ref{fig:clean_scan} and \ref{fig:dirty_scan} show the LAT scans corresponding to $s1$ =

\begin{quote}
    "[INST] Is the hypothesis entailed by the premise? yes or no. [/INST] Premise: Managing better requires that agencies have, and rely upon, sound financial and program information. Hypothesis: Agencies need sound financial and program information for good management."
\end{quote}

and $s2$ = \begin{quote}
    "[INST] Is the hypothesis entailed by the premise? yes or no. [/INST] Premise: Managing better requires that agencies have, and rely upon, sound financial and program information. Hypothesis: Agencies need sound financial and program information for good management \textbf{and green is not red}."
\end{quote} 
each augmented with the continuation generated by the model.


\begin{figure}[h]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{assets/clean_LAC_management.png}
        \caption{LAT scan of a statement not exhibiting an explicit shorcut cue (\textit{clean} scan)}
        \label{fig:clean_scan}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{assets/dirty_LAC_management.png}
        \caption{LAT scan of a statement exhibiting an explicit shorcut cue (\textit{dirty} scan)}
        \label{fig:dirty_scan}
    \end{minipage}

\end{figure}

\noindent In the deepest hidden layers (approximately layers 
-10 to -1), both scans display a strong correlation with the shortcut direction (dark red cells). This suggests that these late layers are intrinsically more sensitive to the shortcut feature, independently of the specific input. At token positions 40-45, the clean scan exhibits a negative correlation with the shortcut direction, whereas the dirty scan shows an extended red band, indicating shortcut activation even in earlier layers. Furthermore, at the final token position (which is expected to summarize the representation of the entire input sequence) the clean scan shows shortcut correlation only in the last layer, while the dirty scan displays it across multiple layers.\\

To gain further insight into the semantic direction captured by the RepReader, the averaged scores $A^{\text{mean}}_{t}$ can be plotted over the corresponding tokens to identify which words correlate most strongly with the learned shortcut direction. Figure \ref{fig:detection} presents the detection results for the $s2$ statement together with its generated continuation, truncated after a fixed number of tokens. Darker green shading indicates stronger alignment with the shortcut direction. Most highlighted tokens appear as isolated occurrences and correspond to common high-frequency words (such as "that", "have", "and") which are likely attributable to noise. Nevertheless, portions of the shortcut cue "and green is not red" also exhibit clear activation, suggesting that the RepReader partially identifies and responds to the shortcut structure present in the input.\\

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{assets/detection_management_dirty.png}
    \caption{Visualization of token-level projection scores onto the shortcut direction, averaged across all hidden layers}
    \label{fig:detection}
\end{figure}

The outcomes of the shortcut detection experiments offer insight into the effectiveness and interpretability of the RepE framework. The presence of consistent shortcut-sensitive activations across multiple layers suggests that such directions are not confined to a small subset of the network. Instead, they appear to be distributed across depth, emerging cumulatively and becoming more pronounced in the later layers. This supports the view that shortcuts in LLMs are not isolated artifacts but reflect broader representational tendencies embedded in the model’s overall geometry. These observations indicate that RepE is a promising, though not yet fully disentangled, interpretability tool for detecting shortcut reliance. Its results highlight both the potential of directional approaches and the inherent complexity of probing model representations through linear interpretive methods.

\subsection{Shortcut Mitigation Results}
\label{sec:mitres}

To evaluate the effectiveness of the RepE-based framework described in Section \ref{sec:method} for mitigating shortcut learning, the Mistral 7B Instruct v0.1 model was evaluated on ICL-based classification tasks both in its base version and under RepControl interventions. Model performance was assessed using standard classification metrics, including accuracy and F1-score.\\

\noindent \textbf{Hyperparameter Search.} A grid search over multiple hyperparameter configurations was conducted to identify effective intervention settings and to analyze the sensitivity of the mitigation performance to different control parameters. Table \ref{tab:hyperparams} summarizes the hyperparameters and the corresponding values explored in the experiments.

\begin{table}[ht]
\centering
\begin{tabular}{p{3.5cm} p{5.5cm} p{3.5cm}}
\toprule
\textbf{Hyperparameter} & \textbf{Description} & \textbf{Values Tested} \\
\midrule
RepReader Type & Method used to extract the shortcut direction from hidden representations & PCA, ClusterMean \\

Control Operator & RepControl operation applied to hidden states & Linear Combination, Piecewise-linear, Projection \\

Intervention Layers & Range of transformer layers where control is applied & \{from -5 to -17\}, \{from -8 to -22\}, \{from -10 to -29\} \\

Representation Token & Token position used for intervention & Last input token \\

Intervention Strength ($\alpha$) & Scaling coefficient controlling the magnitude of the intervention & $\{-1.7,\ -1.5,\ -1.0,$ $-0.5\ \}$ \\

Shot Setting ($k$) & Number of ICL demonstrations per class & $k = 1$ \\

Training shortcut & Type of shortcut cue present in the dataset used to extract the latent direction & Negation, Position, Style \\

Training dataset size & Number of prompt pairs used to extract clean and dirty hidden representations & $\{\ 64,\ 128,\ 256,\ 512\ \}$\\

Training prompt selection & Criterion used to select prompts from the ShortcutSuite training set  & Random, model-failure-only\\

\bottomrule
\end{tabular}
\vspace{6pt}
\caption{Hyperparameter tested for shortcut mitigation experiments.}
\label{tab:hyperparams}
\end{table}

\noindent The hyperparameter search was conducted on the RTE test set using a Weights\&Bias sweep. Several observations can be drawn from the results. First, as shown in Figure \ref{fig:coeffplot}, stronger interventions ($\alpha = -1.7$ or $\alpha = -1.5$) are associated with lower average accuracy scores, whereas the best results, both in terms of average and peak accuracy, are achieved with a moderate intervention strength ($\alpha = -0.5$).  
This suggests that excessively strong suppression of the shortcut direction may also remove task-relevant information that is entangled with the shortcut representation, thereby harming overall performance.  
In contrast, milder interventions appear to strike a better balance by attenuating shortcut reliance while preserving sufficient semantic signal to support correct inference. Regarding the size of the training dataset, no clear monotonic relationship emerges between the number of prompt pairs and model performance. Nevertheless, smaller dataset sizes (64 or 128 prompt pairs) tend to achieve the highest accuracy more frequently across runs. This suggests that even a limited number of randomly sampled contrastive examples may be sufficient to expose dominant shortcut-related signals in the model’s representations, potentially reducing the influence of noise that could otherwise degrade performance.\\

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{assets/NewCoeffAcc.png}
    \caption{Scatter plot of the hyperparameter search runs, generated via Weights \& Bias, showing the achieved accuracy, the $\alpha$ coefficient value and the training dataset size for each run. The blue curve represents the running avverage of the accuracy scores.}
    \label{fig:coeffplot}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{assets/shortcut_types.png}
    \caption{Violin plot showing the distribution of accuracy scores across hyperparameter search runs, grouped by the type of shortcut cue used during RepReading.}
    \label{fig:shortcut_types}
\end{figure}

The type of shortcut cue present in the training prompts also has a noticeable impact on model performance under intervention, as shown in Figure \ref{fig:shortcut_types}.  
In particular, the \textit{Negation} and \textit{Position} shortcut types yield comparable results, with average accuracy scores across runs of $62\%$ and $61\%$, respectively.  
In contrast, the \textit{Style} shortcut leads to a marked drop in performance, with an average accuracy of $58\%$ and worst-case runs reaching as low as $41\%$. This suggests that stylistic transformations may induce more diffuse or less linearly separable shortcut representations, making them harder to isolate and suppress through linear RepControl interventions. Unlike lexical or positional cues, stylistic changes tend to affect broader aspects of the input distribution, potentially entangling shortcut-related signals with task-relevant semantic features and increasing representational overlap.
Restricting the training set to prompt pairs for which the presence of a shortcut cue caused the model to misclassify the example did not result in improved post-intervention performance, while significantly increasing the computational cost of data selection.  
Consequently, random sampling of training prompts was adopted in all subsequent experiments as a more efficient and equally effective strategy.\\

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{assets/DirectionMethod+Operator.png}
    \caption{Bar plot showing the average accuracy across hyperparameter search runs for each combination of RepReader type and RepControl operator.}
    \label{fig:dirop}
\end{figure}

As shown in Figure \ref{fig:dirop}, the performance achieved by different direction extraction methods (RepReader types) and RepControl operators is generally comparable across configurations. However, some consistent trends emerge from the results: PCA-based RepReaders outperform ClusterMean across all operators, and the projection operator achieves the highest overall performance among the tested control strategies. A possible explanation for these observations can be found in the nature of both the representation extraction methods and the control operators. The PCA-based RepReader aim to identify the direction that explain the largest variance across contrastive hidden representations, which, in the shortcut detection setting, may correspond to dominant and consistently activated shortcut-related signals. By aggregating information across many examples without relying on explicit class centroids, PCA is more robust to noise and idiosyncratic variations introduced by individual prompt pairs. In contrast, the ClusterMean approach relies on averaging representations within the clean and shortcut-induced groups, which may be more sensitive to outliers or to residual semantic differences unrelated to the shortcut itself, resulting in less stable directions.\\

Regarding the control operators, the superior performance of the projection approach can be interpreted as a consequence of its conservative nature.  Rather than adding or subtracting a fixed perturbation to the hidden states, projection explicitly removes the component of the representation aligned with the shortcut direction, leaving the remaining subspace unchanged. This minimizes the risk of distorting task-relevant semantic information that may be partially entangled with shortcut features, a risk that is more pronounced for additive operators such as linear combination or piecewise modulation, especially at higher intervention strengths.\\

This interpretation is consistent with prior work on linear feature extraction and representation intervention, which shows that dominant properties of neural representations often emerge as high-variance linear directions.  
At the same time, recent theoretical analyses have demonstrated that modern neural networks, including Large Language Models, encode multiple features in \textit{superposition}, that is, overlapping and non-orthogonal subspaces within the same representational dimensions \citep{elhage2022toymodelssuperposition}.  
Under feature superposition, any linear intervention inevitably affects entangled features. However, projection-based control minimizes this effect by subtracting shortcut-aligned components rather than actively steering representations, resulting in more stable downstream behavior \citep{elazar-etal-2021-amnesic}.\\

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{assets/intervention_layers.png}
    \caption{Box-and-whisker plot of accuracy scores across hyperparameter search runs, grouped by the range of transformer layers targeted by RepControl interventions.}
    \label{fig:layers}
\end{figure}

Lastly, as shown in Figure \ref{fig:layers}, the range of transformer layers at which RepControl is applied has a substantial impact on post-intervention performance.  
Although all tested layer ranges exhibit considerable variability in accuracy across runs, the range spanning layers from $-5$ to $-17$ consistently yields the most reliable results, as indicated by a higher concentration of accuracy scores around $74\%$.  
The range from $-8$ to $-22$ reaches a peak accuracy comparable to that of the $-5$ to $-17$ range; however, it displays significantly higher variance, including the lowest-performing runs observed across all configurations.  
Finally, the widest range, from $-10$ to $-29$, produces the lowest average accuracy overall, suggesting that interventions applied too early across the model may increasingly disrupt task-relevant representations.\\

More generally, a plausible interpretation of these results is that the effectiveness of RepControl is strongly tied to the representational role played by different transformer layers.  
Prior work has shown that in LLMs higher layers tend to encode increasingly abstract, task-specific and decision-relevant information, while lower layers focus more on lexical, syntactic, and surface-level features \citep{rogers-etal-2020-primer}.  
Applying RepControl to a mid-late range of layers (such as $-5$ to $-17$) may therefore allow the intervention to directly influence the model's final decision process, suppressing shortcut-aligned activations at the stage where they are most behaviorally relevant.  In contrast, extending the intervention to earlier layers, as in the wider $-10$ to $-29$ range, may inadvertently disrupt foundational representations that later layers rely on to construct correct semantic interpretations. This effect is exacerbated by the aforementioned phenomenon of feature superposition.
Thus, repeatedly removing components aligned with a shortcut direction across many layers can accumulate unintended side effects through the residual stream, progressively degrading useful signal even when conservative operators such as projection are used.
Overall, these results indicate that effective shortcut mitigation requires a careful balance between targeting layers close enough to the model’s decision circuitry to influence behavior, while avoiding overly broad interventions that risk amplifying the negative effects of representational entanglement.\\


\noindent \textbf{Evaluation Results.} Table \ref{tab:results} reports the performance of the base Mistral-7B-Instruct model and compares it with the best accuracy and F1 scores obtained when shortcut mitigation is enabled using PCA-based RepReading combined with different RepControl operators: linear combination, piecewise-linear modulation and projection. 
Results are presented across the NLP benchmarks test sets described in Section \ref{subsec:datasets}, covering a range of tasks including textual entailment (RTE, MNLI), commonsense reasoning (COPA), sentiment analysis (CR, SST2), word sense disambiguation (WiC), science question answering (ARC) and broad multi-domain evaluation (MMLU).\\

\begin{table}[h!]
\centering
\begin{tabular}{l *{4}{cc}}
\toprule
    & \multicolumn{2}{c}{\textbf{Baseline}}
    & \multicolumn{2}{c}{\textbf{PCA+LinComb}}
    & \multicolumn{2}{c}{\textbf{PCA+PieceLin}}
    & \multicolumn{2}{c}{\textbf{PCA+Proj}} \\
\midrule
    & Acc & F1
    & Acc & F1
    & Acc & F1
    & Acc & F1 \\
\cmidrule(lr){2-3}      % under Baseline
\cmidrule(lr){4-5}      % under PCA + LinComb
\cmidrule(lr){6-7}      % under PCA + PieceLin
\cmidrule(lr){8-9}      % under PCA + Proj
\textbf{RTE}
    & 0.787 & 0.784 & 0.805 & 0.800 & \textbf{0.834} & \textbf{0.832} & 0.823 & 0.822 \\
\textbf{MNLI}
    & 0.598 & 0.488 & 0.622 & 0.503 & 0.594 & 0.516 & \textbf{0.644} & \textbf{0.538} \\
\textbf{COPA}
    & 0.820 & 0.820 & \textbf{0.880} & \textbf{0.879} & 0.870 & 0.867 & \textbf{0.880} & \textbf{0.879} \\
\textbf{CR}
    & 0.925 & 0.918 & \textbf{0.939} & \textbf{0.933} & 0.931 & 0.924 & 0.926 & 0.918 \\
\textbf{SST2}
    & 0.948 & 0.948 & \textbf{0.953} & \textbf{0.953} & 0.952 & 0.952 & 0.950 & 0.949 \\
\textbf{WIC}
    & 0.497 & 0.348 & 0.525 & 0.450 & \textbf{0.547} & \textbf{0.533} & 0.508 & 0.406 \\
\textbf{ARC}
    & 0.675 & 0.674 & \textbf{0.685} & \textbf{0.684} & 0.682 & 0.680 & 0.677 & 0.676 \\
\textbf{MMLU}
    & 0.485 & 0.485 & 0.513 & 0.513 & \textbf{0.530} & \textbf{0.528} & 0.524 & 0.524 \\
\midrule
\textbf{Avg.}
 & 0.717 & 0.683
    & 0.740 & 0.715
    & \textbf{0.742} & \textbf{0.729}
    & 0.742 & 0.714 \\
\bottomrule
\end{tabular}
\vspace{6pt}
\caption{\label{tab:results} Best accuracy and F1 scores obtained for the base Mistral-7B-Instruct model and three RepControl configurations using the PCA representation reader with the following operators: linear combination (LinComb), piecewise-linear transformation (PieceLin) and projection (Proj).}
\end{table}

In particular, the reported results correspond to the best-performing configuration identified during the hyperparameter search.  
For each benchmark, the highest accuracy and F1 scores were selected among those obtained under different RepControl settings.  
Specifically, the shortcut direction was extracted from the ShortcutSuite dataset targeting either the \textit{Negation} or \textit{Position} shortcut cue, using training sets of 64 or 128 contrastive prompt pairs.  
RepControl interventions were applied to transformer layers ranging from $-5$ to $-17$, with the intervention strength coefficient set to $\alpha = -0.5$.\\

Overall, every RepControl configuration yield some improvements over the baseline across all evaluated tasks, indicating that suppressing shortcut-aligned directions extracted via PCA can positively influence model behavior even beyond the task and dataset used for representation extraction.  
On average, RepControl increases accuracy from $0.717$ to approximately $0.74$, with gains both on tasks where shortcut reliance is known to be more pronounced or where baseline performance is relatively low (e.g. MNLI, WiC and MMLU) and on tasks with stronger baseline performance such as COPA, where shortcut mitigation leads to marked improvements despite the already high initial accuracy.\\

A closer inspection reveals that no single operator dominates across all tasks, although some consistent patterns emerge.  
For textual entailment benchmarks, PCA combined with piecewise-linear modulation achieves the strongest results on RTE, while PCA with projection performs best on MNLI.  
This suggests that different entailment datasets may rely on distinct shortcut mechanisms: RTE, being smaller and more lexically constrained, may benefit from conditional amplification or suppression of shortcut-aligned activations, whereas MNLI, with its greater diversity and complexity, appears to favor the more conservative removal of shortcut components through projection, which minimizes unintended interference with task-relevant representations.\\

For sentiment-related tasks (CR and SST2), RepControl yields smaller yet consistent improvements over the baseline.  
These tasks already exhibit strong baseline performance, leaving limited room for improvement; nevertheless, the observed gains indicate that shortcut suppression does not interfere with, and may even slightly enhance, robust semantic reasoning when shortcuts overlap with superficial signals such as sentiment-bearing words.  
In this setting, the linear combination operator performs particularly well, suggesting that mild additive adjustments are sufficient to rebalance representations without removing task-relevant information.\\

More challenging tasks such as WiC and MMLU show some of the largest relative improvements, especially when using the piecewise-linear operator.  
These benchmarks require fine-grained semantic distinctions or broad domain knowledge and are therefore more sensitive to spurious correlations and heuristic decision strategies.  
The effectiveness of piecewise-linear control in this context may stem from its conditional nature, which selectively amplifies or suppresses shortcut-aligned activations depending on their alignment with the current hidden representation, enabling a more adaptive intervention than purely additive or subtractive approaches.\\

Taken together, these results support the central hypothesis of this work: shortcut-related mechanisms can be captured as latent directions in the representation space of LLMs and selectively manipulated to improve performance across tasks.  
At the same time, the variability observed across datasets and RepControl operators highlights that different forms of representational control may be required depending on how shortcut cues are encoded and entangled with task-relevant information.\\ 

A particularly noteworthy observation is that, although the shortcut direction was extracted using shortcut cues specifically designed for the textual entailment task, its manipulation consistently led to performance improvements across a diverse set of heterogeneous NLP benchmarks.  
This suggests that the extracted direction does not merely encode task-specific artifacts of textual entailment, but instead captures a more general representational tendency of the model to rely on superficial or spurious correlations when making predictions. A plausible interpretation is that shortcut reliance reflects a shared internal mechanism through which LLMs exploit easily accessible heuristics, such as lexical overlap, stylistic patterns, or positional regularities. Although these shortcuts manifest differently at the input level in tasks such as sentiment analysis, commonsense reasoning, or word sense disambiguation, they may be implemented internally through overlapping representational subspaces that bias the model toward shallow decision strategies.  
From this perspective, the shortcut direction extracted in the textual entailment setting can be interpreted as capturing a higher-level inductive bias of the model, rather than a narrow task-specific feature. However, the variability in gains across tasks indicates that shortcut reliance is not fully task-agnostic: different benchmarks may engage this shared mechanism to different extents, or may encode task-relevant information with varying degrees of entanglement with shortcut-aligned features.\\

\noindent \textbf{Aggregation of Multiple Shortcut Types.} To investigate whether shortcut mitigation can be made more robust by accounting for multiple shortcut mechanisms simultaneously, an additional set of experiments was conducted in which shortcut directions extracted from different shortcut types (namely \textit{Negation} and \textit{Position}) were combined into a single intervention signal.
The directions were aggregated using a simple normalized sum strategy. For each target layer, all available shortcut directions were first individually $\ell_2$-normalized to remove scale effects and prevent any single shortcut from dominating due to magnitude alone. The normalized directions were then summed and the resulting vector was normalized again, yielding a single composite shortcut direction per layer. This procedure preserves the relative orientation of the different shortcut signals while maintaining a bounded norm, making it compatible with the RepControl intervention mechanism.
By intervening along this aggregated direction, the model is encouraged to suppress a broader class of shortcut-aligned features simultaneously, rather than targeting a single, narrowly defined heuristic.
This experiment therefore serves as a preliminary test of whether shortcut mitigation can generalize from single-cue interventions toward a more holistic control of shortcut-prone representational patterns.\\

However, the resulting performance on the RTE benchmark was consistently lower than both the baseline model and the best single-shortcut interventions.
Specifically, the baseline Mistral-7B-Instruct model achieves an accuracy of $0.787$ on RTE, while the best RepControl configurations based on a single shortcut direction reach accuracies above $0.83$. In contrast, the aggregated-shortcut interventions yield accuracies in the range of approximately $0.72$-$0.80$, with an average accuracy of $0.746$, failing to match the baseline and substantially underperforming compared to single-shortcut control. This degradation suggests that naively combining shortcut directions through a normalized sum does not lead to additive benefits.\\ 

A plausible explanation is that different shortcut types are not perfectly aligned in representation space. Although they may share high-level inductive biases toward shallow heuristics, their corresponding latent directions can partially conflict or overlap with task-relevant features in distinct ways. Aggregating them into a single control vector may therefore attenuate useful components or suppress information that is necessary for correct entailment judgments, leading to degraded performance rather than improved robustness. Overall, these findings highlight an important limitation of linear representation-level control: while effective at targeting dominant shortcut mechanisms individually, it does not trivially scale to the joint mitigation of heterogeneous shortcuts. They suggest that more structured or adaptive strategies, such as shortcut-specific control directions, weighted or learned aggregation schemes, or non-linear intervention mechanisms, may be required to robustly suppress multiple shortcuts behaviors without compromising task performance.


\subsection{Qualitative Analysis}

This section presents additional qualitative experiments aimed at complementing the quantitative evaluation of the proposed shortcut mitigation approach.  
The goal of these analyses is to assess whether the observed performance improvements are driven by the intended causal mechanisms (namely the suppression of shortcut-related representations) rather than by incidental or fortunate side effects.  
At the same time, these experiments serve to evaluate the interpretability of the proposed method by examining how representation-level interventions affect model behavior in specific, illustrative cases.\\

\noindent \textbf{RepControl effect on classification labels.} The RepControl intervention designed to mitigate shortcut learning was evaluated on selected input examples in order to qualitatively assess its impact on full model generations under representations steering.  

\begin{tcolorbox}[
  colback=gray!5,
  colframe=black!50,
  boxrule=0.3pt,
  arc=2pt,
  title={Model behavior under shortcut mitigation},
  fonttitle=\bfseries
]
\textbf{Input:}\\
$\left[INST\right]$ Is the hypothesis entailed by the premise? yes or no. $\left[/INST\right]$
\textit{Premise}: Fruit, vegetables, electronics, and a little bit of everything else is on sale here. 
\textit{Hypothesis}: You can buy all sorts of products and food here and green is not red.

\vspace{0.6em}

\textbf{Baseline Output:}\\
Answer: No, the hypothesis is not entailed by the premise. The premise does not provide any information about the colors of the products on sale, so it is not possible to conclude that green is not red based on the


\vspace{0.4em}

\textbf{RepControl Output:}\\
Yes, the hypothesis is entailed by the premise. The premise mentions that various types of products and food are available for purchase, which supports the hypothesis that one could potentially buy a variety of items at this location.
\end{tcolorbox}

\vspace{1em}

\noindent The responses in the example reported above were obtained using, in the first case, the baseline model, and in the second case a controlled version of the model in which shortcut-aligned activations extracted via PCA from 128 contrastive prompt pairs from the ShortcutSuite dataset targeting the Negation shortcut were suppressed through linear combination with strength coefficient $\alpha = -0.5$, with the intervention applied to transformer layers ranging from $-5$ to $-17$.
To allow inspection of the model’s natural language explanations for its classification decisions while keeping the computational cost of generation limited, the outputs are truncated after the first 50 generated tokens.\\

This example illustrates that suppressing the shortcut-aligned direction successfully alters the model’s decision, leading it to correctly recognize the entailment relation despite the presence of a negation-based distractor in the hypothesis.  
Notably, the baseline response explicitly refers to the lexical elements associated with the negation shortcut cue (i.e. “green is not red”), whereas the controlled response ignores these superficial signals and completes a logically coherent reasoning process grounded in the semantic content of the premise. This observation further indicates that the RepControl intervention does not impair the model’s ability to generate fluent and meaningful natural language, but rather selectively modulates the decision-relevant components of its internal representations.\\

The following example instead uses a positive strength coefficient $\alpha = +1.5$ in order to examine the effects of amplifying the shortcut-aligned direction rather than suppressing it. 

\begin{tcolorbox}[
  colback=gray!5,
  colframe=black!50,
  boxrule=0.3pt,
  arc=2pt,
  title={Model behavior under shortcut amplification},
  fonttitle=\bfseries
]
\textbf{Input:}\\
$\left[INST\right]$ Is the hypothesis entailed by the premise? yes or no. $\left[/INST\right]$
\textit{Premise}: Children will enjoy the little steam train that loops around the bay to Le Crotoy in the summer.
\textit{Hypothesis}: There is a steam train looping around the bay to Le Crotoy and false is not true.

\vspace{0.6em}

\textbf{Baseline Output:}\\
Yes, the hypothesis is entailed by the premise.
\vspace{0.4em}

\textbf{RepControl Output:}\\
The two statements are not related, so the hypothesis is not entailed by the premise.
\end{tcolorbox}

\vspace{1em}
\noindent In this case, the baseline model correctly predicts entailment despite the presence of a negation-based shortcut cue in the hypothesis. However, when the shortcut-aligned direction is amplified through RepControl, the model’s prediction is flipped to an incorrect non-entailment decision. This behavior provides additional evidence that the extracted latent direction indeed corresponds to shortcut-related mechanisms: increasing its activation strength biases the model toward a shortcut-driven interpretation, while suppressing it (as shown in the previous example) promotes more semantically grounded reasoning. Neither response includes an explicit natural language explanation of the classification decision, and under shortcut amplification the model’s output no longer strictly follows the expected response format, as it does not begin with an explicit \textit{yes} or \textit{no} token.  
This deviation suggests that strong positive interventions may interfere not only with the model’s decision boundary but also with higher-level generation patterns, further underscoring the importance of carefully tuning the intervention strength $\alpha$ when applying RepControl.\\


Finally, the following example illustrates a failure case of the proposed shortcut mitigation approach, obtained under the same hyperparameter configuration as the first example, highlighting the limits of the intervention even in settings where it is generally effective.

\begin{tcolorbox}[
  colback=gray!5,
  colframe=black!50,
  boxrule=0.3pt,
  arc=2pt,
  title={Failure case under shortcut mitigation},
  fonttitle=\bfseries
]
\textbf{Input:}\\
$\left[INST\right]$ Is the hypothesis entailed by the premise? yes or no. $\left[/INST\right]$
\textit{Premise}: A group of guys went out for a drink after work, and sitting at the bar was a real a 6 foot blonde with a fabulous face and figure to match.
\textit{Hypothesis}: A stunning six foot blonde woman sat at the bar with the men after work and no square is a circle.

\vspace{0.6em}

\textbf{Baseline Output:}\\
Answer: No, the hypothesis is not entailed by the premise. The premise does not provide any information about the woman's personality or character, and the hypothesis is not related to the premise in any
\vspace{0.4em}

\textbf{RepControl Output:}\\
Based on the information provided in the premise, it is not clear whether the hypothesis is entailed by the premise. The premise describes a scenario involving a group of men going out for a drink and encountering a beautiful woman at
\end{tcolorbox}

\vspace{1em}
\noindent In this example, the RepControl intervention does not fully succeed in correcting the model’s prediction, which remains uncertain, likely due to the presence of a negation-based shortcut cue in the hypothesis.  
Nevertheless, a qualitative difference can be observed in the controlled generation: compared to the baseline output, the model appears less decisive, producing a more tentative response rather than a confident categorical judgment. This behavior suggests that, although the shortcut-aligned direction was not sufficiently suppressed to fully reverse the decision, the intervention still affects the model’s internal confidence.  
Such partial effects may indicate that, in this instance, shortcut-related features are more strongly entangled with task-relevant semantic information, or that additional shortcut dimensions beyond the single extracted direction contribute to the model’s decision process.\\

\begin{figure}[ht]
    \centering

    \begin{subfigure}[t]{0.65\linewidth}
        \centering
        \includegraphics[width=\linewidth]{assets/confusion-1.5.png}
        \caption{$\alpha = -1.5$}
        \label{fig:conf_alpha_neg}
    \end{subfigure}

    \vspace{1em}

    \begin{subfigure}[t]{0.65\linewidth}
        \centering
        \includegraphics[width=\linewidth]{assets/confusion-0.5.png}
        \caption{$\alpha = -0.5$}
        \label{fig:conf_alpha_mid}
    \end{subfigure}

    \vspace{1em}

    \begin{subfigure}[t]{0.65\linewidth}
        \centering
        \includegraphics[width=\linewidth]{assets/confusion+1.5.png}
        \caption{$\alpha = +1.5$}
        \label{fig:conf_alpha_pos}
    \end{subfigure}

    \caption{Multi-run confusion matrices of the hyperparameter search evaluation runs on the RTE dataset illustrating the effect of RepControl intervention strength on model predictions.}
    \label{fig:confusion_alpha}
\end{figure}

To further characterize the effect of RepControl on classification behavior, multi-run confusion matrices were computed from evaluation runs of the hyperparameter search on the RTE dataset (Figure \ref{fig:confusion_alpha}).  
These matrices summarize the distribution of predicted labels under different intervention strengths and provide a global view of how representation-level control reshapes the model’s decision patterns. The results reveal a systematic relationship between the intervention coefficient and the model’s output distribution.  
When a large negative coefficient is applied ($\alpha = -1.5$), predictions collapse predominantly toward the \textit{entailment} class, whereas a large positive coefficient ($\alpha = +1.5$) induces the opposite behavior, biasing the model almost entirely toward \textit{contradiction}.  
This symmetric and monotonic shift provides strong evidence that the extracted shortcut direction is directionally faithful and causally connected to the model’s decision boundary, rather than acting as a source of random noise or incidental regularization.\\

At the same time, these results highlight the importance of carefully tuning the strength of the intervention.  
While moderate coefficients (e.g. $\alpha = -0.5$) improve classification balance and overall performance, extreme values lead to degenerate decision policies in which the model over-relies on the manipulated direction at the expense of task-relevant semantic information.  
A potential failure mode of representation-level control is therefore that the extracted direction may act as a trivial label-forcing mechanism, biasing the model toward a fixed class rather than improving semantic reasoning. However, the quantitative results presented in the previous section, obtained using a moderate intervention strength, show consistent improvements in both accuracy and F1 score across multiple datasets and tasks with different label spaces and class distributions.  
This behavior is difficult to reconcile with a fixed-class bias, since always predicting a dominant class would typically increase accuracy only under severe class imbalance while simultaneously degrading F1, particularly for minority classes. Overall, while extreme interventions demonstrate that RepControl \emph{can} collapse predictions, the moderate settings used for shortcut mitigation yield non-trivial benefits that are more consistent with a selective reduction of shortcut reliance than with naive label forcing.\\

\noindent \textbf{Token-level attribution via Integrated Gradients.}
To analyze how individual input tokens contribute to the model’s predictions and how these contributions change under RepControl intervention, the \textit{Integrated Gradients} (IG) attribution method was employed.
Integrated Gradients is a gradient-based interpretability technique that assigns an importance score to each input feature by integrating the gradients of the model’s output with respect to the input along a straight-line path between a baseline input (i.e. a reference point with minimal semantic content) and the actual input \citep{sundararajan2017axiomaticattributiondeepnetworks}.\\

Formally, given a model $F(\cdot)$, an input embedding $x \in \mathbb{R}^{T \times d}$ (with $T$ tokens and embedding dimension $d$) and a baseline embedding $x'$, the Integrated Gradients attribution for the $i$-th input dimension is defined as:
\begin{equation}
\mathrm{IG}_i(x) = (x_i - x'_i) \cdot \int_{\alpha=0}^{1} 
\frac{\partial F\!\left(x' + \alpha (x - x')\right)}{\partial x_i} \, d\alpha
\end{equation}

In practice, the integral is approximated via a Riemann sum over $m$ discrete interpolation steps:
\begin{equation}
\mathrm{IG}_i(x) \approx (x_i - x'_i) \cdot \frac{1}{m} 
\sum_{k=1}^{m} 
\frac{\partial F\!\left(x' + \frac{k}{m} (x - x')\right)}{\partial x_i}
\end{equation}

In this work, the baseline $x'$ is chosen as the embedding of the beginning-of-sequence token, which provides a stable and semantically neutral reference compared to an all-zero embedding.
At each interpolation step, gradients are computed with respect to the embedding vectors, and the resulting attributions are summed across the embedding dimension to obtain a scalar importance score for each token:
\begin{equation}
\mathrm{IG}_{\text{token}}(t) = \sum_{j=1}^{d} \mathrm{IG}_{t,j}
\end{equation}

Specifically, attributions are calculated for the logit corresponding to a chosen class (e.g. \textit{entailment}), allowing the analysis to focus on which tokens contribute to supporting that decision. 
This choice is particularly relevant in the context of shortcut learning, where spurious cues are expected to disproportionately influence the confidence of specific labels.  By keeping the target label fixed before and after RepControl intervention, changes in token attributions can be directly interpreted as shifts in the internal evidence used by the model. This enables a fine-grained assessment of whether shortcut mitigation suppresses shortcut-aligned token importance while preserving semantically meaningful contributions.\\

\begin{figure}[ht]
    \centering

    \begin{subfigure}[t]{1\linewidth}
        \centering
        \includegraphics[width=\linewidth]{assets/attributions_red.png}
        \caption{Top 25 tokens ranked by the absolute change in Integrated Gradients attribution between the baseline model and the RepControl-intervened model.}
    \end{subfigure}

    \vspace{1em}

    \begin{subfigure}[t]{1\linewidth}
        \centering
        \includegraphics[width=\linewidth]{assets/change_importance.png}
        \caption{Heatmap of token-level attribution differences (RepControl minus baseline), highlighting how RepControl redistributes importance across the input sequence.}
    \end{subfigure}

    \caption{Visualization of the token-level attributions computed via Integrated Gradients for the class \textit{entailment} with input "$\left[INST\right]$ Is the hypothesis entailed by the premise? yes or no. $\left[/INST\right]$
\textit{Premise}: Fruit, vegetables, electronics, and a little bit of everything else is on sale here. 
\textit{Hypothesis}: You can buy all sorts of products and food here and green is not red."}
    \label{fig:attributions}
\end{figure}

Figure \ref{fig:attributions} reports the token-level attributions computed via Integrated Gradients for the \textit{entailment} class on the first qualitative example discussed in the previous section, comparing the baseline model with its RepControl-modified counterpart.  
In the baseline setting, a large fraction of the attribution mass is assigned to shortcut-related lexical cues, most notably the token \textit{``red''}, which appears in the tautological negation phrase appended to the hypothesis.  
This indicates that the model relies heavily on the presence of shortcut-related tokens when supporting the entailment decision, rather than grounding its prediction in the semantic overlap between premise and hypothesis. After applying RepControl with a negative intervention strength, the importance of shortcut-aligned tokens is substantially reduced.  
In particular, the attribution associated with \textit{``red''} and with the negation-related token \textit{``no''} decreases markedly, while the relative contribution of semantically meaningful tokens such as \textit{``vegetables''} and \textit{``products''} slightly increases, even though their overall attribution values remain negative. This redistribution suggests that suppressing the shortcut-aligned latent direction encourages the model to rely less on superficial lexical cues and more on content-bearing elements of the input when forming its decision. At the same time, the attribution maps reveal non-negligible noise introduced by the intervention. Some punctuation symbols (e.g. \textit{``:''}, \textit{``.''}) receive increased attribution despite carrying no semantic relevance for the entailment relation, and the negative contribution associated with the token \textit{``green''} is further amplified rather than fully suppressed.\\

While these results provide evidence that RepControl can reduce the influence of dominant shortcut cues, they also highlight several limitations of the proposed approach. First, the redistribution of attribution mass is not perfectly aligned with semantic relevance: some tokens that are logically irrelevant to the entailment relation, such as punctuation symbols, receive increased importance after intervention, indicating that RepControl may introduce secondary artifacts in the attribution patterns. Moreover, the fact that certain shortcut-related tokens retain or even increase their influence suggests that shortcut reliance is not fully captured by a single linear direction.  
Instead, shortcut mechanisms are likely distributed across multiple entangled features in the representation space, making them only partially suppressible through linear interventions. As a result, RepControl appears to attenuate the dominant shortcut signal without completely disentangling it from task-relevant semantic representations. More generally, these observations underline a key limitation of representation-level control methods based on linear directions: while effective at modulating coarse-grained behavioral tendencies, they provide only an approximate handle on the complex and highly superposed internal representations of LLMs.\\

\noindent \textbf{Non-Linearity Analysis.} To better understand the observed limitations of the proposed linear shortcut mitigation framework, we analyze the \emph{intrinsic dimensionality} (ID) of the model’s hidden representations across different transformer layers.
Intrinsic dimensionality refers to the minimum number of degrees of freedom required to describe the data locally, that is, the dimension of the underlying manifold on which the representations lie, independently of the ambient embedding space dimension. If shortcut-related representations are organized along highly curved or non-linear manifolds, linear methods such as PCA may provide only an approximate characterization, potentially limiting the effectiveness of extracting a single shortcut direction.\\

To this end, the intrinsic dimensionality is estimated using both a linear and a non-linear approach.
In the linear case, ID is approximated as the number of principal components required to explain 95\% of the total variance of the representations.
This measure captures how many orthogonal linear directions are needed to reconstruct the data, but it implicitly assumes that the underlying structure is approximately linear. In contrast, a non-linear estimate of intrinsic dimensionality is obtained using the Two Nearest Neighbors (TwoNN) method \citep{Facco_2017}.
TwoNN is based on minimal neighborhood information: for each data point, it considers the ratio between the distances to its first and second nearest neighbors.
Under mild assumptions, the distribution of these ratios depends only on the intrinsic dimensionality of the data manifold, allowing ID to be estimated without assuming linearity or constructing a global embedding of the data.
As a result, TwoNN is well-suited to detect low-dimensional but curved structures that may not be well captured by PCA.\\

By comparing the linear (PCA-based) and non-linear (TwoNN-based) intrinsic dimensionality estimates, we assess whether hidden representations at different layers are well approximated by locally linear subspaces or instead exhibit significant non-linear structure.
Large discrepancies between the two estimates indicate layers where the representation geometry is highly non-linear, suggesting that shortcut-related features may be distributed across curved manifolds rather than concentrated along a single linear direction. The results reported in Table \ref{tab:intrinsic_dim_heatmap} are obtained from the hidden representations produced by the Mistral 7B Instruct model for 128 \textit{clean} and \textit{dirty} prompts derived from the ShortcutSuite dataset targeting the Negation shortcut type.\\

\begin{table}[ht]
\centering
\small
\setlength{\tabcolsep}{3.8pt}
\renewcommand{\arraystretch}{1.15}

\begin{tabular}{ccccc|cccc}
\toprule
\multirow{2}{*}{Layer} &
\multicolumn{4}{c|}{\textbf{Clean Representations}} &
\multicolumn{4}{c}{\textbf{Dirty Representations}} \\

\cmidrule(lr){2-5} \cmidrule(lr){6-9}

 & PCA & TwoNN & PC1 var & PCA/TwoNN
 & PCA & TwoNN & PC1 var & PCA/TwoNN \\

\midrule
-1  & 55 & 16.47 & 0.191 & \ratioheat{3.34}
    & 58 & 14.95 & 0.182 & \ratioheat{3.88} \\

-5  & 89 & 19.79 & 0.096 & \ratioheat{4.50}
    & 89 & 19.39 & 0.099 & \ratioheat{4.59} \\

-10 & 96 & 20.74 & 0.133 & \ratioheat{4.63}
    & 97 & 24.85 & 0.133 & \ratioheat{3.90} \\

-15 & 98 & 20.22 & 0.122 & \ratioheat{4.85}
    & 99 & 25.30 & 0.117 & \ratioheat{3.91} \\

-20 & 97 & 20.73 & 0.103 & \ratioheat{4.68}
    & 97 & 18.65 & 0.101 & \ratioheat{5.20} \\

-25 & 99 & 22.49 & 0.102 & \ratioheat{4.40}
    & 100 & 19.95 & 0.100 & \ratioheat{5.01} \\

-31 & 102 & 28.69 & 0.102 & \ratioheat{3.56}
    & 103 & 25.80 & 0.101 & \ratioheat{3.99} \\

\bottomrule
\end{tabular}

\vspace{6pt}
\caption{Intrinsic dimensionality estimates for clean and dirty representations across transformer layers, computed using linear (\textit{PCA}) and non-linear (\textit{TwoNN}) methods. 
\textit{PC1 var} denotes the fraction of variance explained by the first principal component. 
The heatmap encodes the ratio between linear and non-linear intrinsic dimensionality (\textit{PCA/TwoNN}), highlighting the degree of curvature of the underlying representation manifold.}
\label{tab:intrinsic_dim_heatmap}
\end{table}

Across all examined layers, both clean and dirty representations exhibit a large gap between the dimensionality required to explain $95\%$ of the variance via PCA and the intrinsic dimensionality estimated by the non-linear TwoNN method.
In particular, PCA dimensionality ranges from approximately $55$ in the final layer to over $100$ in earlier layers, while TwoNN consistently estimates a much lower intrinsic dimensionality, typically between $15$ and $30$.
The resulting PCA/TwoNN ratios, highlighted in the heatmap, indicate that shortcut-related representations lie on low-dimensional but strongly curved manifolds, rather than on approximately linear subspaces. An additional informative signal is provided by the variance explained by the first principal component, which accounts for only a limited fraction of the total variance, with PC1 values ranging roughly between $10\%$ and $19\%$.
This suggests that, although shortcut-related representations are intrinsically low-dimensional, they are not dominated by a single linear direction. Instead, the variance is distributed across multiple correlated components, consistent with the presence of feature superposition and non-linear structure in the residual stream. This observation explains why PCA-based extraction of a shortcut direction can be effective in aggregate, by capturing a prominent axis of variation, while still failing to fully isolate shortcut mechanisms at the level of individual examples.\\

Beyond the overall gap between linear and non-linear dimensionality estimates, Table \ref{tab:intrinsic_dim_heatmap} reveals a systematic difference in how geometric complexity evolves across layers for clean versus dirty representations.
For clean representations, the PCA / TwoNN ratio exhibits a relatively smooth and structured trend: non-linearity increases from the early layers toward the mid layers (approximately $-31$ to $-15$), before decreasing again in late layers.
This pattern suggests a staged representational process in which shortcut-free inputs are progressively transformed into increasingly abstract but structured manifolds, before being consolidated into more stable configurations closer to the input.
Such behavior is consistent with prior findings that intermediate layers in transformer models encode richer and more compositional abstractions, while both early and late layers tend to exhibit more constrained geometries. In contrast, dirty representations display a markedly less regular behavior. While their average intrinsic dimensionality remains comparable to that of clean representations, the PCA/TwoNN ratio fluctuates substantially across layers, with pronounced peaks in curvature at specific depths (e.g. around layers $-20$ and $-25$). These localized spikes may indicate that shortcut cues induce irregular distortions of the representational manifold, increasing its curvature in a layer-dependent and input-dependent manner rather than following a smooth transformation trajectory. This “chaotic” geometric behavior suggests that shortcut learning does not merely strengthen an existing low-dimensional feature, but instead perturbs the internal representation in ways that are less globally organized and more entangled with other semantic features, biasing the model’s traversal of an underlying representational manifold, rather than by activating isolated, linearly separable features.\\

From the perspective of shortcut mitigation, this distinction is critical. Linear representation control methods such as PCA-based RepControl are naturally better suited to structured, approximately linear manifolds, as observed for clean representations and for certain layer ranges in dirty ones.
However, the presence of highly curved, layer-specific distortions in shortcut-contaminated representations limits the effectiveness of a single global linear direction, helping to explain both the variability in mitigation performance across layers and the existence of failure cases observed in the qualitative analysis. These findings reinforce the interpretation that shortcut learning introduces localized non-linear deformations in the model’s internal geometry, motivating future work on layer-adaptive or non-linear representation control mechanisms.


\subbib{}
\end{document}

