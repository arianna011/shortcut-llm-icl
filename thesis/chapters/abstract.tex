\documentclass[../main.tex]{subfiles}
\graphicspath{{\subfix{../assets/}}}
\begin{document}

\begin{abstract}
% problem
While Large Language Models (LLMs) are extremely powerful and versatile tools, their robustness and interpretability are undermined by shortcut learning, a phenomenon that leads models to rely on spurious correlations between inputs and outputs rather than following a logical reasoning process.\\

% scope
This work investigates strategies to detect and mitigate shortcut learning in LLMs, focusing on Natural Language Processing (NLP) tasks under an In-Context Learning (ICL) setting. The ICL paradigm introduces new opportunities for shortcuts to arise, as models may exploit superficial cues in example prompts - such as lexical overlap or word order -  rather than acquiring the intended task structure.\\

% motivation
Addressing shortcut learning is essential not only for improving the reliability and generalization of LLMs, but also for mitigating harmful biases that might promote ethically problematic behaviors, including the unfair treatment of particular social groups. 
\end{abstract}

\subbib{}
\end{document}