\documentclass[../main.tex]{subfiles}
% !TeX root = ../main.tex
\graphicspath{{\subfix{../assets/}}}
\begin{document}

\chapter{TODO}

\section{Representation Engineering}

Representation Engineering (RepE) \citep{zou2025representationengineeringtopdownapproach} is a novel approach to the interpretability analysis of Large Language Models (LLMs). It aims to enhance human understanding of their internal behaviors, both enabling a more effective use and mitigating the risks posed by hidden erroneous mechanisms, which represent a critical hazard given the growing pervasiveness of AI across society.\\

RepE finds theoritical grounding in the \textit{Hopfieldian} view of cognitive neuroscience, which interprets cognition as computation over representational spaces emerging from the activity of neural populations, abstracting away the specific connections betweeen individual neurons. This perspective focuses on high-level cognitive phenomena, contrasting with the \textit{Sherringtonian} view, which centers on single neurons and node-to-node interactions \citep{cognitivescience}. While the field of Mechanistic Interpretability\footnote{A branch of AI research that seeks to "reverse-engineer" neural networks by explaining their outputs in terms of circuits and algorithms} adopts a Sherringtonian-like, bottom-up approach by studying the relations between hidden units (e.g. attention heads or MLP neurons) and model behaviors, RepE proposes a complementary top-down interpretation of LLMs. It aims to link emergent phenomena within models to their hidden representations, which have been shown to become increasingly semantically structured across layers \citep{tenney2019bertrediscoversclassicalnlp}. This may overcome the limits of bottom-up approaches in capturing complex and distributed effects in large networks, emphasizing how LLMs encode human concepts in latent spaces rather than focusing on their specific neural architecture.

\end{document}