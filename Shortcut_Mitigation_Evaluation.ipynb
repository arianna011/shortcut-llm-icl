{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0PKTfWoeMP8"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sN_hwwlWm4HH"
      },
      "outputs": [],
      "source": [
        "!pip -q install transformers accelerate datasets essential-generators bitsandbytes tqdm google-generativeai tiktoken orjson tenacity pandasgui wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOhhaBsYeHDV",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Clone GitHub repo\n",
        "\n",
        "import os, shutil, getpass\n",
        "from google.colab import drive\n",
        "\n",
        "update_repo_copy = True #@param {type:\"boolean\"}\n",
        "REPO_NAME = \"shortcut-llm-icl\" #@param {type:\"string\"}\n",
        "\n",
        "DIR_NAME = 'Tesi Computer Science/ShortcutProject'  #@param {type:\"string\"}\n",
        "DRIVE_PATH = '/content/drive/MyDrive/' + DIR_NAME + '/'\n",
        "TARGET_DIR = os.path.join(DRIVE_PATH, REPO_NAME)\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "if update_repo_copy or not os.path.exists(TARGET_DIR):\n",
        "  GITHUB_USER = input(\"Enter GitHub username: \").strip()\n",
        "  GITHUB_TOKEN = getpass.getpass(\"Enter GitHub token: \").strip()\n",
        "  GITHUB_URL = f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{REPO_NAME}.git\"\n",
        "  TEMP_CLONE_DIR = f\"/content/{REPO_NAME}\"\n",
        "\n",
        "  if os.path.exists(TEMP_CLONE_DIR):\n",
        "      shutil.rmtree(TEMP_CLONE_DIR)\n",
        "\n",
        "  print(f\"Cloning {REPO_NAME} into Colab RAM...\")\n",
        "  exit_code = os.system(f'git clone \"{GITHUB_URL}\" \"{TEMP_CLONE_DIR}\"')\n",
        "\n",
        "  if exit_code == 0:\n",
        "      print(f\"Copying to Google Drive → {TARGET_DIR}\")\n",
        "      if os.path.exists(TARGET_DIR):\n",
        "          shutil.rmtree(TARGET_DIR)\n",
        "      shutil.copytree(TEMP_CLONE_DIR, TARGET_DIR)\n",
        "\n",
        "      # remove repo from RAM to save space\n",
        "      shutil.rmtree(TEMP_CLONE_DIR)\n",
        "      print(\"✅ Done.\")\n",
        "  else:\n",
        "      print(\"❌ Clone failed. Check token, username or repo visibility.\")\n",
        "\n",
        "%cd \"{TARGET_DIR}\"\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "import getpass\n",
        "import shlex\n",
        "import os\n",
        "import torch\n",
        "import wandb\n",
        "from patched_unibias import WB_logging as L\n",
        "from extract_activations import HuggingFaceLLM, RepE_evaluation, ShortcutAggregation\n",
        "\n",
        "HuggingFaceLLM.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "gaPbg_EriLCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXvWByfzpYCQ"
      },
      "outputs": [],
      "source": [
        "#@title Login Hugging Face\n",
        "os.environ[\"HF_TOKEN\"] = getpass.getpass(\"Enter Hugging Face token: \")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Login Weights&Bias\n",
        "os.environ[\"WANDB_API_KEY\"] = getpass.getpass(\"Enter W&B API key: \")\n",
        "!wandb login $WANDB_API_KEY"
      ],
      "metadata": {
        "id": "XHWq_oeSnHih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate complete RepE pipeline"
      ],
      "metadata": {
        "id": "du-EFHL9JKEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load target LLM\n",
        "TARGET_MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.1\" #@param {type: \"string\"}\n",
        "MODEL_WRAP = HuggingFaceLLM(TARGET_MODEL_NAME, os.environ[\"HF_TOKEN\"], quantize=True)"
      ],
      "metadata": {
        "id": "Vbnb4vea3myc",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup parameters\n",
        "\n",
        "REPO_PATH = TARGET_DIR\n",
        "OVERWRITE_DATASET_WB = False #@param {type: \"boolean\"}\n",
        "OVERWRITE_ACTIVATIONS_WB = False #@param {type: \"boolean\"}\n",
        "\n",
        "TRAINING_DATASET_NAME = \"ShortcutSuite\" #@param [\"ShortcutSuite\"]\n",
        "NEGATION_SHORTCUT = True #@param {type: \"boolean\"}\n",
        "POSITION_SHORTCUT = False #@param {type: \"boolean\"}\n",
        "STYLE_SHORTCUT = False #@param {type: \"boolean\"}\n",
        "\n",
        "TRAINING_DATASET_SHORTCUTS = []\n",
        "if NEGATION_SHORTCUT:\n",
        "  TRAINING_DATASET_SHORTCUTS.append(\"negation\")\n",
        "if POSITION_SHORTCUT:\n",
        "  TRAINING_DATASET_SHORTCUTS.append(\"position\")\n",
        "if STYLE_SHORTCUT:\n",
        "  TRAINING_DATASET_SHORTCUTS.append(\"style_bible\")\n",
        "\n",
        "SHORTCUT_AGGREGATION = \"NONE\" #@param [\"NONE\", \"NORMALIZED_SUM\"]\n",
        "if SHORTCUT_AGGREGATION  != \"NONE\":\n",
        "  SHORTCUT_AGGREGATION = ShortcutAggregation[SHORTCUT_AGGREGATION]\n",
        "else:\n",
        "  SHORTCUT_AGGREGATION = None\n",
        "\n",
        "TRAINING_DATASET_SIZE = 64 #@param {type: \"integer\"}\n",
        "TRAINING_DATASET_SEL_METHOD = \"RANDOM\" #@param [\"RANDOM\", \"MODEL_FAILS\", \"MODEL_FAILS_ON_SPECIFIC_LABELS\"]\n",
        "TRAINING_DATASET_SEL_METHOD = L.SelectionMethod[TRAINING_DATASET_SEL_METHOD]\n",
        "TRAINING_DATASET_RANDOM_SEED = 20 #@param {type: \"integer\"}\n",
        "TRAINING_BATCH_SIZE = 32 #@param {type: \"integer\"}\n",
        "TRAINING_DEBUG = False #@param {type: \"boolean\"}\n",
        "\n",
        "ACTIVATIONS_CLEAN_INSTR = \"Decide if the hypothesis is entailed by the premise.\" #@param {type: \"string\"}\n",
        "ACTIVATIONS_DIRTY_INSTR = \"Decide if the hypothesis is entailed by the premise.\" #@param {type: \"string\"}\n",
        "ACTIVATIONS_DATA_SHUFFLE = True #@param {type: \"boolean\"}\n",
        "ACTIVATIONS_DIRECTION_METHOD = \"pca\" #@param [\"pca\", \"cluster_mean\"]\n",
        "ACTIVATIONS_ALPHA_COEFF = -0.5 #@param {type: \"slider\", min:-5.0, max: 5.0, step:0.1}\n",
        "\n",
        "EVAL_DATASET = \"rte\" #@param [\"rte\", \"mnli\", \"mmlu\", \"copa\", \"trec\", \"cr\", \"wic\", \"sst2\", \"arc\"]\n",
        "EVAL_NUM_SHOT = 1 #@param {type: \"slider\", min:0, max: 2, step:1}\n",
        "EVAL_INTERVENTION_LAYERS = \"-5 -6 -7 -8 -9 -10 -11 -12 -13 -14 -15 -16 -17\" #@param {type: \"string\"}\n",
        "EVAL_INTERVENTION_LAYERS = list(map(int, EVAL_INTERVENTION_LAYERS.split()))\n",
        "EVAL_OPERATOR = \"linear_comb\" #@param [\"linear_comb\", \"piecewise_linear\", \"projection\"]\n",
        "EVAL_RESUME = False #@param {type: \"boolean\"}\n"
      ],
      "metadata": {
        "id": "qM4bvuCv2Jz9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run evaluation\n",
        "RepE_evaluation(\n",
        "    repo_path=REPO_PATH,\n",
        "    drive_path=DRIVE_PATH,\n",
        "    overwrite_df_artifact=OVERWRITE_DATASET_WB,\n",
        "    overwrite_act_artifact=OVERWRITE_ACTIVATIONS_WB,\n",
        "    training_dataset_name=TRAINING_DATASET_NAME,\n",
        "    training_dataset_size=TRAINING_DATASET_SIZE,\n",
        "    training_dataset_shortcut_types=TRAINING_DATASET_SHORTCUTS,\n",
        "    shortcut_aggregation=SHORTCUT_AGGREGATION,\n",
        "    training_dataset_sel_method=TRAINING_DATASET_SEL_METHOD,\n",
        "    training_dataset_random_seed=TRAINING_DATASET_RANDOM_SEED,\n",
        "    training_batch_size=TRAINING_BATCH_SIZE,\n",
        "    training_debug=TRAINING_DEBUG,\n",
        "    activations_clean_instr=ACTIVATIONS_CLEAN_INSTR,\n",
        "    activations_dirty_instr=ACTIVATIONS_DIRTY_INSTR,\n",
        "    activations_data_shuffle=ACTIVATIONS_DATA_SHUFFLE,\n",
        "    activations_direction_method=ACTIVATIONS_DIRECTION_METHOD,\n",
        "    activations_alpha_coeff=ACTIVATIONS_ALPHA_COEFF,\n",
        "    model_wrap=MODEL_WRAP,\n",
        "    eval_dataset_name=EVAL_DATASET,\n",
        "    eval_num_shot=EVAL_NUM_SHOT,\n",
        "    eval_intervention_layers=EVAL_INTERVENTION_LAYERS,\n",
        "    eval_operator=EVAL_OPERATOR,\n",
        "    eval_resume=EVAL_RESUME)"
      ],
      "metadata": {
        "id": "fHeHo7AY4d98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run hyperparameter search"
      ],
      "metadata": {
        "id": "f9kXE9A_6QN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "existing_sweep_id_to_resume = ''  #@param {type: 'string'}\n",
        "EVAL_DATASET = \"mnli\" #@param [\"rte\", \"mnli\", \"mmlu\"]\n",
        "PROMPT_SELECTION_METHOD = \"RANDOM\"\n",
        "RANDOM_SEED = 20\n",
        "\n",
        "SWEEP_NAME = f\"{EVAL_DATASET}_{TARGET_MODEL_NAME}_RepE_eval\"\n",
        "\n",
        "sweep_config = {\n",
        "    'name': SWEEP_NAME,\n",
        "    'method': 'grid',\n",
        "    'metric': {\n",
        "        'name': 'accuracy',\n",
        "        'goal': 'maximize',\n",
        "    },\n",
        "    'parameters': {\n",
        "        'activations_alpha_coeff' : {\n",
        "             'values': [-0.5]\n",
        "        },\n",
        "        'direction_method': {\n",
        "            'values': ['pca']\n",
        "        },\n",
        "        'activations_data_shuffle': {\n",
        "            'values': [True]\n",
        "        },\n",
        "        'overwrite_dataset_wb': {\n",
        "            'values': [False]\n",
        "        },\n",
        "        'overwrite_activations_wb': {\n",
        "            'values': [False]\n",
        "        },\n",
        "        'training_dataset_random_seed': {'values': [RANDOM_SEED]},\n",
        "        'training_dataset_shortcuts': {\n",
        "            'values': [\"negation\", \"position\"]\n",
        "        },\n",
        "        'eval_operator': {\n",
        "            'values': [\"piecewise_linear\", \"projection\"]\n",
        "        },\n",
        "        \"training_dataset_sel_method\" : { 'values': [PROMPT_SELECTION_METHOD] } ,\n",
        "        \"training_dataset_size\" : { 'values': [64, 128] } ,\n",
        "        'eval_intervention_layers': {\n",
        "            'values': [\n",
        "                list(range(-5,-18,-1))\n",
        "                ] }\n",
        "    }\n",
        "}\n",
        "\n",
        "if existing_sweep_id_to_resume:\n",
        "  print('Resuming Sweep with ID', existing_sweep_id_to_resume)\n",
        "  sweep_id = f'{L.WB_TEAM}/{L.WB_PROJECT_NAME}/{existing_sweep_id_to_resume}'\n",
        "  print(f'Sweep URL: https://wandb.ai/{L.WB_TEAM}/{L.WB_PROJECT_NAME}/sweeps/{existing_sweep_id_to_resume}')\n",
        "else:\n",
        "  sweep_id = wandb.sweep(sweep_config, entity=f'{L.WB_TEAM}', project=f'{L.WB_PROJECT_NAME}')"
      ],
      "metadata": {
        "id": "rcZiKUGnKKaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_with_wandb():\n",
        "    with wandb.init() as run:\n",
        "        cfg = wandb.config\n",
        "\n",
        "        def get_value(key_lower):\n",
        "            \"\"\"\n",
        "            Try to get the lowercase key from wandb.config,\n",
        "            otherwise fall back to the matching UPPERCASE global variable.\n",
        "            \"\"\"\n",
        "            if key_lower in cfg:\n",
        "                return cfg[key_lower]\n",
        "            upper_key = key_lower.upper()\n",
        "            if upper_key in globals():\n",
        "                return globals()[upper_key]\n",
        "            raise KeyError(f\"Missing parameter: {key_lower} (no config or global)\")\n",
        "\n",
        "        selection_method = get_value(\"training_dataset_sel_method\")\n",
        "        if isinstance(selection_method, str):\n",
        "            selection_method = L.SelectionMethod[selection_method]\n",
        "\n",
        "        try:\n",
        "          RepE_evaluation(\n",
        "              repo_path=get_value(\"repo_path\"),\n",
        "              drive_path=get_value(\"drive_path\"),\n",
        "              overwrite_df_artifact=get_value(\"overwrite_dataset_wb\"),\n",
        "              overwrite_act_artifact=get_value(\"overwrite_activations_wb\"),\n",
        "              training_dataset_name=get_value(\"training_dataset_name\"),\n",
        "              training_dataset_size=get_value(\"training_dataset_size\"),\n",
        "              training_dataset_shortcut_types=get_value(\"training_dataset_shortcuts\"),\n",
        "              shortcut_aggregation=get_value(\"shortcut_aggregation\"),\n",
        "              training_dataset_sel_method=selection_method,\n",
        "              training_dataset_random_seed=get_value(\"training_dataset_random_seed\"),\n",
        "              training_batch_size=get_value(\"training_batch_size\"),\n",
        "              training_debug=get_value(\"training_debug\"),\n",
        "              activations_clean_instr=get_value(\"activations_clean_instr\"),\n",
        "              activations_dirty_instr=get_value(\"activations_dirty_instr\"),\n",
        "              activations_data_shuffle=get_value(\"activations_data_shuffle\"),\n",
        "              activations_direction_method=get_value(\"activations_direction_method\"),\n",
        "              activations_alpha_coeff=get_value(\"activations_alpha_coeff\"),\n",
        "              model_wrap=get_value(\"model_wrap\"),\n",
        "              eval_dataset_name=get_value(\"eval_dataset\"),\n",
        "              eval_num_shot=get_value(\"eval_num_shot\"),\n",
        "              eval_intervention_layers=get_value(\"eval_intervention_layers\"),\n",
        "              eval_operator=get_value(\"eval_operator\"),\n",
        "              eval_resume=get_value(\"eval_resume\"),\n",
        "          )\n",
        "        except Exception as e:\n",
        "           print(f\"⚠️ Run failed: {e}\")\n"
      ],
      "metadata": {
        "id": "Gxpp4kKf6oz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run sweep\n",
        "wandb.agent(sweep_id, function=eval_with_wandb)"
      ],
      "metadata": {
        "id": "P6WKA_6q5NQ_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}